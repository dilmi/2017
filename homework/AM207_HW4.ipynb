{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Homework 4 - Nam Wook Kim (90948148)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## APMTH 207:  Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "\n",
    "**Due Date:** Thursday, Febrary 23rd, 2017 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as well as your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 1: Optimization (Continued)\n",
    "\n",
    "Suppose you are building a pricing model for laying down telecom cables over a geographical region. Your model takes as input a pair of  coordinates, $(x, y)$, and contains two parameters, $\\lambda_1, \\lambda_2$. Given a coordinate, $(x, y)$, and model parameters, the loss in revenue corresponding to the price model at location $(x, y)$ is described by\n",
    "$$\n",
    "L(x, y, \\lambda_1, \\lambda_2) = 0.000045\\lambda_2^2 y - 0.000098\\lambda_1^2 x + 0.003926\\lambda_1 x\\exp\\left\\{\\left(y^2 - x^2\\right)\\left(\\lambda_1^2 + \\lambda_2^2\\right)\\right\\}\n",
    "$$\n",
    "Read the data contained in `HW3_data.csv`. This is a set of coordinates configured on the curve $y^2 - x^2 = -0.1$. Given the data, find parameters $\\lambda_1, \\lambda_2$ that minimize the net loss over the entire dataset.\n",
    "\n",
    "### Part A: Further problems with descent algorithms\n",
    "Using your implementation of gradient descent and stochastic gradient descent, document the behaviour of your two algorithms for the following starting points, and for a number of stepsizes of your choice:\n",
    "- $(\\lambda_1, \\lambda_2) = (-2.47865, 0)$\n",
    "- $(\\lambda_1, \\lambda_2) = (-3, 0)$\n",
    "- $(\\lambda_1, \\lambda_2) = (-5, 0)$\n",
    "- $(\\lambda_1, \\lambda_2) = (-10, 0)$\n",
    "\n",
    "Based on your analysis of the loss function $L$, explain what is happening to your descent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "import time\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x, y = np.genfromtxt('HW3_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_sum = x.sum()\n",
    "y_sum = y.sum()\n",
    "N = len(x)\n",
    "\n",
    "#Total loss\n",
    "L = lambda l1, l2, x, y: 0.000045 * l2**2 * y.sum() - 0.000098 * l1**2 * x.sum() + 0.003926 * x.sum() * l1 * np.exp(-0.1 * (l1**2 + l2**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The gradient of the total loss function\n",
    "grad = lambda l1, l2, x, y: np.array([-0.000098 * 2 * l1 * x.sum() \n",
    "                                      + 0.003926 *  x.sum() * np.exp(-0.1 * (l1**2 + l2**2)) \n",
    "                                      - 0.003926 * 2 * 0.1 *  x.sum() * l1**2 * np.exp(-0.1 * (l1**2 + l2**2)), \n",
    "                                      2 * 0.000045 * l2 * y.sum() \n",
    "                                      - 0.1 * 2* 0.003926 *  x.sum() * l1 * l2 * np.exp(-0.1 * (l1**2 + l2**2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "def gradient_descent(x, y, lambdas_init, init_shuffle=False, step_size=0.001, maxsteps=None, precision=1e-3, scaling=1.):\n",
    "    \n",
    "    lambdas = lambdas_init\n",
    "    history = [lambdas] # to store all parameters\n",
    "    counter = 0\n",
    "\n",
    "    #if you want to shuffle the data before doing descent\n",
    "    if init_shuffle:\n",
    "        shuffle = np.random.permutation(N)\n",
    "        x = x[shuffle]\n",
    "        y = y[shuffle]\n",
    "\n",
    "    #Do descent while stopping condition not met\n",
    "    while np.linalg.norm(history[-1] - np.array([2.05384, 0])) > precision:\n",
    "        #get gradient of average loss function\n",
    "        gradient = grad(lambdas[0], lambdas[1], x, y) * 1. / N\n",
    "        #take one step in the gradient direction, scaling is just a scaling factor that adjusts the stepsize\n",
    "        #of course you can just directly adjust the stepsize\n",
    "        lambdas = lambdas -  step_size * gradient * scaling \n",
    "        #add our new parameters to the history\n",
    "        history.append(lambdas)\n",
    "        #tick off one more step\n",
    "        counter +=1\n",
    "        \n",
    "        #if we've hit maximum steps allowed, stop!\n",
    "        if maxsteps is not None:\n",
    "            if counter == maxsteps:\n",
    "                break\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent\n",
    "def sgd(x, y, lambdas_init, init_shuffle=False, step_size=0.001, max_epochs=1, precision=1e-3, scaling=1.):\n",
    "    lambdas = lambdas_init\n",
    "    history = [lambdas] # to store all thetas\n",
    "\n",
    "    counter = 0\n",
    "    epochs = 0\n",
    "    i = 0 #index\n",
    "        \n",
    "    #if you want to shuffle the data before doing descent\n",
    "    if init_shuffle:\n",
    "        shuffle = np.random.permutation(N)\n",
    "        x = x[shuffle]\n",
    "        y = y[shuffle]    \n",
    "    \n",
    "    #run through the data in multiple passes\n",
    "    for epoch in range(max_epochs):\n",
    "        #for each data point, compute the gradient and make an update to our parameters\n",
    "#         print 'epoch: ', epoch \n",
    "        for i in range(N):\n",
    "            #get gradient of average loss function\n",
    "            gradient = grad(lambdas[0], lambdas[1], x[i], y[i])\n",
    "            #take one step in the gradient direction, scaling is just a scaling factor that adjusts the stepsize\n",
    "            #of course you can just directly adjust the stepsize\n",
    "            lambdas = lambdas -  step_size * gradient * scaling \n",
    "            #add our new parameters to the history\n",
    "            history.append(lambdas)   \n",
    "            \n",
    "            if np.linalg.norm(np.array(lambdas) - np.array([2.05384, 0])) < precision:\n",
    "                return history, epoch\n",
    "            elif np.any(np.isnan(lambdas)):\n",
    "                return history[:-1], epoch\n",
    "        \n",
    "        #shuffle the data for the next pass thru\n",
    "        shuffle = np.random.permutation(N)\n",
    "        x = x[shuffle]\n",
    "        y = y[shuffle]\n",
    "    \n",
    "    return history, max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test(lambdas_inits, step_size=0.001):\n",
    "    print '\\n---------------------- step_size:', step_size, '----------------------\\n'\n",
    "    gd_losses = []\n",
    "    sgd_losses = []\n",
    "    for lambdas_init in lambdas_inits:\n",
    "        print '\\n****************** lambda init:', lambdas_init, '******************\\n'\n",
    "        print '1. GD'\n",
    "        history = gradient_descent(x, y, lambdas_init, step_size=step_size, scaling=1000., maxsteps=100000)\n",
    "        history = np.array(history)\n",
    "\n",
    "        lambdas = history[-1]\n",
    "        costs = L(history[:, 0], history[:, 1], x, y)\n",
    "\n",
    "        print '- how many iters: ', len(history)\n",
    "        print '- final cost:', costs[-1]\n",
    "        print '- precision to actual param:', np.linalg.norm(lambdas - [2.05384, 0])\n",
    "        print '\\n'\n",
    "\n",
    "        gd_losses.append(costs[-1])\n",
    "\n",
    "        print '2. SGD'\n",
    "        history, epoch = sgd(x, y, lambdas_init, init_shuffle=True, step_size=step_size, max_epochs=8, scaling=1000.)\n",
    "        history = np.array(history)\n",
    "\n",
    "        lambdas = history[-1]\n",
    "        costs = L(history[:, 0], history[:, 1], x, y) \n",
    "\n",
    "        print '- how many iters: ', len(history)\n",
    "        print '- final cost:', costs[-1]\n",
    "        print '- precision to actual param:', np.linalg.norm(lambdas - [2.05384, 0])\n",
    "        print '\\n'\n",
    "\n",
    "        sgd_losses.append(costs[-1])\n",
    "        \n",
    "    return gd_losses, sgd_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- step_size: 0.1 ----------------------\n",
      "\n",
      "\n",
      "****************** lambda init: [-2.47865, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  25460\n",
      "- final cost: -9.93410204361\n",
      "- precision to actual param: 0.000877201161326\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-3, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  6586\n",
      "- final cost: -9.93410402225\n",
      "- precision to actual param: 2.69640235571e-05\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-5, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  44577\n",
      "- final cost: -9.93410223605\n",
      "- precision to actual param: 0.000833079970987\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-10, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  39221\n",
      "- final cost: -9.93410369133\n",
      "- precision to actual param: 0.000372891185811\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWSYODjMzy8TBYWZmmfx/Fb59k1rfTE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10374a9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas_inits = [[-2.47865,0], [-3,0], [-5,0], [-10,0]]\n",
    "\n",
    "step_size = 0.1\n",
    "gd_losses, sgd_losses = test(lambdas_inits, step_size)\n",
    "\n",
    "ind = np.arange(len(gd_losses))\n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, gd_losses, width, color='r')\n",
    "rects2 = ax.bar(ind + width, sgd_losses, width, color='b')\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss. Step size='+str(step_size))\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('[-2.47865,0]', '[-3,0]', '[-5, 0]', '[-10, 0]'))\n",
    "ax.legend((rects1[0], rects2[0]), ('GD', 'SGD'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- step_size: 0.01 ----------------------\n",
      "\n",
      "\n",
      "****************** lambda init: [-2.47865, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926027\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 11.9545803086\n",
      "- precision to actual param: 4.53248625197\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-3, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926027\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 11.9545803086\n",
      "- precision to actual param: 4.53248625197\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-5, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926027\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-10, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niXMQmJklzkFgZpa4/w+4jBo43pXT6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10375b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas_inits = [[-2.47865,0], [-3,0], [-5,0], [-10,0]]\n",
    "\n",
    "step_size = 0.01\n",
    "gd_losses, sgd_losses = test(lambdas_inits, step_size)\n",
    "\n",
    "ind = np.arange(len(gd_losses))\n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, gd_losses, width, color='r')\n",
    "rects2 = ax.bar(ind + width, sgd_losses, width, color='b')\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss. Step size='+str(step_size))\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('[-2.47865,0]', '[-3,0]', '[-5, 0]', '[-10, 0]'))\n",
    "ax.legend((rects1[0], rects2[0]), ('GD', 'SGD'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- step_size: 0.001 ----------------------\n",
      "\n",
      "\n",
      "****************** lambda init: [-2.47865, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16251470164\n",
      "- precision to actual param: 7.38334433089\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 11.9545803086\n",
      "- precision to actual param: 4.53248625197\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-3, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152870393\n",
      "- precision to actual param: 7.41701665634\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 11.9545803086\n",
      "- precision to actual param: 4.53248625197\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-5, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152869942\n",
      "- precision to actual param: 7.41708202146\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n",
      "\n",
      "****************** lambda init: [-10, 0] ******************\n",
      "\n",
      "1. GD\n",
      "- how many iters:  100001\n",
      "- final cost: 8.16152873345\n",
      "- precision to actual param: 7.41728772702\n",
      "\n",
      "\n",
      "2. SGD\n",
      "- how many iters:  128001\n",
      "- final cost: 8.16152869937\n",
      "- precision to actual param: 7.41708926028\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncIstBmOoG9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108262890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas_inits = [[-2.47865,0], [-3,0], [-5,0], [-10,0]]\n",
    "\n",
    "step_size = 0.001\n",
    "gd_losses, sgd_losses = test(lambdas_inits, step_size)\n",
    "\n",
    "ind = np.arange(len(gd_losses))\n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, gd_losses, width, color='r')\n",
    "rects2 = ax.bar(ind + width, sgd_losses, width, color='b')\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss. Step size='+str(step_size))\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('[-2.47865,0]', '[-3,0]', '[-5, 0]', '[-10, 0]'))\n",
    "ax.legend((rects1[0], rects2[0]), ('GD', 'SGD'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Maybe I am wrong, but it is difficult to see any significant trends across different initial parameters. \n",
    "\n",
    "For the step size 0.01 and 0.001, SGD seems to decrease in loss as the init param is further away from the global minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part B: Simulated Annealing\n",
    "Implement Simulated Annealing initalized at $(\\lambda_1, \\lambda_2) = (-5, 0)$ to minimize our lost function $L$. Compare your results to what you obtained for gradient descent and stochastic gradient descent initialized at $(\\lambda_1, \\lambda_2) = (-5, 0)$.\n",
    "\n",
    "For your Simulated Annealing implementation, we suggest *starting* with following settings for parameters (you should further experiment with and tweak these or feel free to set your own):\n",
    "\n",
    "- Proposal distribution: bivariate normal with covariance $[[1, 0], [0, 1]]$\n",
    "- Min Length: 500\n",
    "- Max Temperature: 10\n",
    "\n",
    "You should also set your own cooling schedule.\n",
    "\n",
    "**Extra Credit**\n",
    "For each temperature, plot the parameters accepted or the cost function with respect to the iteration number. What is happening to the these parameters or costs over iterations? Connect the trends you observe in the visualization to the lecture on Markov Chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# proposal distribution\n",
    "pfxs = lambda s, x: x + s*np.random.multivariate_normal([0,0],[[1,0],[0,1]])\n",
    "pf = partial(pfxs, 0.1)\n",
    "\n",
    "tf = lambda t: 0.8*t #temperature function\n",
    "itf = lambda length: int(math.ceil(1.2*length)) #iteration function\n",
    "\n",
    "f = partial(L, x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sa(ef, inits, epochs, tf, itf, pf):\n",
    "    acc = []\n",
    "    best_sol = old_sol = inits['sol']\n",
    "    T = inits['T']\n",
    "    length = inits['len']\n",
    "    best_eng = old_eng = ef(*old_sol)\n",
    "    accepted = 0\n",
    "    total = 0\n",
    "    for i in xrange(epochs):\n",
    "        print 'Epoch', i\n",
    "        if i>0:\n",
    "            T = tf(T)\n",
    "            length = itf(length)\n",
    "        print 'T:', T, ', Length:', length\n",
    "        for it in xrange(length):\n",
    "            total+=1\n",
    "            new_sol = pf(old_sol)\n",
    "            new_eng  = ef(*new_sol)\n",
    "            alpha = min(1, np.exp((old_eng-new_eng)/T))\n",
    "            if ((new_eng < old_eng) or (np.random.uniform() < alpha)):\n",
    "                accepted +=1\n",
    "                acc.append((T, new_sol, new_eng))\n",
    "                if new_eng < best_eng:\n",
    "                    best_eng = new_eng\n",
    "                    best_sol = new_sol\n",
    "                    best_idx = total\n",
    "                    best_temp = T \n",
    "                old_eng = new_eng\n",
    "                old_sol = new_sol\n",
    "            else:\n",
    "                acc.append((T,old_sol,old_eng))\n",
    "                \n",
    "    best_meta = dict(index = best_idx, temp = best_temp)\n",
    "    print(\"frac accepted\", accepted/total, \"total iterations\", total, 'bmeta', best_meta)\n",
    "    return best_meta, best_sol, best_eng, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "T: 10 , Length: 500\n",
      "Epoch 1\n",
      "T: 8.0 , Length: 600\n",
      "Epoch 2\n",
      "T: 6.4 , Length: 720\n",
      "Epoch 3\n",
      "T: 5.12 , Length: 864\n",
      "Epoch 4\n",
      "T: 4.096 , Length: 1037\n",
      "Epoch 5\n",
      "T: 3.2768 , Length: 1245\n",
      "Epoch 6\n",
      "T: 2.62144 , Length: 1494\n",
      "Epoch 7\n",
      "T: 2.097152 , Length: 1793\n",
      "Epoch 8\n",
      "T: 1.6777216 , Length: 2152\n",
      "Epoch 9\n",
      "T: 1.34217728 , Length: 2583\n",
      "Epoch 10\n",
      "T: 1.073741824 , Length: 3100\n",
      "Epoch 11\n",
      "T: 0.8589934592 , Length: 3720\n",
      "Epoch 12\n",
      "T: 0.68719476736 , Length: 4464\n",
      "Epoch 13\n",
      "T: 0.549755813888 , Length: 5357\n",
      "Epoch 14\n",
      "T: 0.43980465111 , Length: 6429\n",
      "Epoch 15\n",
      "T: 0.351843720888 , Length: 7715\n",
      "Epoch 16\n",
      "T: 0.281474976711 , Length: 9258\n",
      "Epoch 17\n",
      "T: 0.225179981369 , Length: 11110\n",
      "Epoch 18\n",
      "T: 0.180143985095 , Length: 13332\n",
      "Epoch 19\n",
      "T: 0.144115188076 , Length: 15999\n",
      "Epoch 20\n",
      "T: 0.115292150461 , Length: 19199\n",
      "Epoch 21\n",
      "T: 0.0922337203685 , Length: 23039\n",
      "Epoch 22\n",
      "T: 0.0737869762948 , Length: 27647\n",
      "Epoch 23\n",
      "T: 0.0590295810359 , Length: 33177\n",
      "Epoch 24\n",
      "T: 0.0472236648287 , Length: 39813\n",
      "Epoch 25\n",
      "T: 0.037778931863 , Length: 47776\n",
      "Epoch 26\n",
      "T: 0.0302231454904 , Length: 57332\n",
      "Epoch 27\n",
      "T: 0.0241785163923 , Length: 68799\n",
      "Epoch 28\n",
      "T: 0.0193428131138 , Length: 82559\n",
      "Epoch 29\n",
      "T: 0.0154742504911 , Length: 99071\n",
      "('frac accepted', 0, 'total iterations', 591884, 'bmeta', {'index': 61943, 'temp': 0.22517998136852502})\n"
     ]
    }
   ],
   "source": [
    "inits=dict(sol=[-5,0], len=500, T=10)\n",
    "bmeta, bs, be, out = sa(f, inits, 30, tf, itf, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.05374087e+00,   1.60707616e-04])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.9341039630229275"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- final cost: -9.93410396302\n",
      "- precision to actual param: 0.000188821922947\n"
     ]
    }
   ],
   "source": [
    "print '- final cost:', be\n",
    "print '- precision to actual param:', np.linalg.norm(bs - [2.05384, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is comparable to that of SGD (step size = 0.1, init = [-5,0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
