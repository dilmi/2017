{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Long Homework 1 - <font color='##1abc9c'>Nam Wook Kim (90948148)</font>\n",
    "\n",
    "## AMPTH 207: Stochastic Methods for Data Analysis, Inference and Optimization\n",
    " \n",
    "**Due Date:** Thursday, February 23rd, 2017 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as well as your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Premise\n",
    "\n",
    "In supervised machine learning, a function that maps certain input data to a set of outputs is inferred from a labelled dataset called the training set, and the resulting learnt funtion is then used to make predictions on unseen new examples of the dataset (the test set).\n",
    "\n",
    "The goal of this homework is to construct a classifier known as the single-hidden-layer Multi-Layer Perceptron (MLP), an artificial neural netwok. You are asked to train the classifier using mini-batch gradient descent, validate it, and then apply it to a test dataset to make predictions. We will use the [*MNIST* dataset](https://en.wikipedia.org/wiki/MNIST_database), which consists of 70,000 images of handwritten digits, each of which is 28x28 pixels. You can use the first 50,000 images as the training set, the next 10,000 images as the validation set, and the last 10,000 images as the test set.\n",
    "\n",
    "You will proceed in 2 steps (each step is a problem) to build the MLP. Please use Theano to program the classifiers.\n",
    "\n",
    "## Problem 1. Stochastic gradient descent for the logistic regresion\n",
    "\n",
    "First, build a logistic regression classifier whose input is the array of pixel values in one image, and whose output is the most likely class of the vector. In order to familiarize yourself with the dataset, plot some of the images beforehand, and think about the pixel values as features of the input vector.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Using the softmax formulation, write a Theano expression graph that:\n",
    "* Calculates the probability of a target element belonging to class $i$ (i.e., the probability that a given image represents a digit between 0 and 9).\n",
    "* Maximizes it over all classes, and computes the cost function using an L2 regularization approach\n",
    "* Minimizes the resulting cost function using mini-batch gradient descent. How long does it take for your code to train with 50,000 training examples of the dataset?\n",
    "\n",
    "*Hint: Use a batch size of 256 examples, a learning rate $\\eta = 0.1$, and a regularization factor $\\lambda=0.01$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import *\n",
    "import theano.tensor as T\n",
    "import six.moves.cPickle as pickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "import six.moves.cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = pickle.load(gzip.open('mnist.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABSCAYAAABE4S/MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11467de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,6)\n",
    "ax[0].imshow(train_set[0][0,:].reshape(28,28), cmap='gray')\n",
    "ax[1].imshow(train_set[0][1,:].reshape(28,28), cmap='gray')\n",
    "ax[2].imshow(train_set[0][2,:].reshape(28,28), cmap='gray')\n",
    "ax[3].imshow(train_set[0][3,:].reshape(28,28), cmap='gray')\n",
    "ax[4].imshow(train_set[0][4,:].reshape(28,28), cmap='gray')\n",
    "ax[5].imshow(train_set[0][5,:].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def models(n_in, n_out, eta, reg):\n",
    "    # initialize parameters with zeros (w: weights, b: bias)\n",
    "    w = theano.shared(value = np.zeros((n_in, n_out), dtype=theano.config.floatX), name='w', borrow=True)\n",
    "    b = theano.shared(value = numpy.zeros((n_out,),dtype=theano.config.floatX), name='b', borrow=True)\n",
    "\n",
    "    # input\n",
    "    x = T.dmatrix(\"x\")\n",
    "\n",
    "    # output\n",
    "    y = T.lvector(\"y\")\n",
    "\n",
    "    # probability for class-membership\n",
    "    p_y_given_x = T.nnet.softmax(T.dot(x,w)+b) \n",
    "\n",
    "    # the prediction model\n",
    "    prediction = T.argmax(p_y_given_x, axis=1) \n",
    "\n",
    "    # loss function\n",
    "    loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  \n",
    "\n",
    "\n",
    "    # The cost to minimize\n",
    "    cost = loss.mean() + reg * (w ** 2).sum()      \n",
    "\n",
    "\n",
    "    # gradient\n",
    "    gw = T.grad(cost=cost, wrt=w)\n",
    "    gb = T.grad(cost=cost, wrt=b) \n",
    "\n",
    "\n",
    "    # training model    \n",
    "    train = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],\n",
    "              updates=((w, w - eta * gw), (b, b - eta * gb)),name='train')\n",
    "\n",
    "    # validate model\n",
    "    validate = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],name='validate')\n",
    "\n",
    "    # test model\n",
    "    test = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],name='test')\n",
    "\n",
    "    # predict\n",
    "    predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "    \n",
    "    return train, validate, test, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training 50,000 examples: 0.4853\n",
      "- Batch size: 256\n",
      "- Learning rate: 0.1\n",
      "- Regularization lambda: 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input image size\n",
    "n_in=28 * 28 \n",
    "\n",
    "# class size (0~9)\n",
    "n_out=10\n",
    "\n",
    "# learning rate\n",
    "eta = 0.1\n",
    "\n",
    "# regularization parameter\n",
    "reg = 0.01\n",
    "\n",
    "# batch size\n",
    "batch_size = 256\n",
    "\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "\n",
    "train, validate, test, predict = models(n_in, n_out, eta, reg)\n",
    "\n",
    "# Train with 50,000 examples\n",
    "start_time = time.time() \n",
    "\n",
    "for index in range(n_train_batches):\n",
    "    # Now for the update we only use one mini-batch at a time\n",
    "    pred, err = train(train_set[0][index * batch_size: (index + 1) * batch_size], \\\n",
    "                      train_set[1][index * batch_size: (index + 1) * batch_size])\n",
    "        \n",
    "\n",
    "print 'Time taken for training 50,000 examples: {:.4f}'.format(time.time() - start_time)\n",
    "print '- Batch size: 256'\n",
    "print '- Learning rate: 0.1'\n",
    "print '- Regularization lambda: 0.01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "* Evaluate the validation loss function periodically as you train the classifier and plot it as a function of the epoch. Plot this loss function for several values of the regularization factor.\n",
    "* When should you stop the training for different values of $\\lambda$? Give an approximate answer supported by using the plots.\n",
    "* Select what you consider the best regularization factor and predict the classes of the test set. Compare with the given labels. What is the test error that you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 1\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  1.0000 - Time taken: 30.6489\n",
      "reg 0.1\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  0.1000 - Time taken: 30.9502\n",
      "reg 0.01\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  0.0100 - Time taken: 31.0567\n",
      "reg 0.001\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  0.0010 - Time taken: 29.8647\n",
      "reg 0.0001\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  0.0001 - Time taken: 29.1488\n",
      "reg 1e-05\n",
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n",
      "Reg:  0.0000 - Time taken: 31.4415\n"
     ]
    }
   ],
   "source": [
    "# epochs\n",
    "n_epochs = 5\n",
    "\n",
    "# regularization params\n",
    "regs = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "# Train\n",
    "error_valid = {}\n",
    "times = {}\n",
    "for reg in regs:\n",
    "    print 'reg', reg\n",
    "    error_valid[reg] = []\n",
    "    train, validate, test, predict = models(n_in, n_out, eta, reg)\n",
    "    start_time = time.time()\n",
    "    for i in xrange(n_epochs):\n",
    "        print '--- epoch',i\n",
    "        for index in xrange(n_train_batches):\n",
    "            # Now for the update we only use one mini-batch at a time\n",
    "            pred, err = train(train_set[0][index * batch_size: (index + 1) * batch_size], \\\n",
    "                              train_set[1][index * batch_size: (index + 1) * batch_size])\n",
    "\n",
    "            errores = []             \n",
    "            # Now we check the performance on the validation set, every 2 batches.\n",
    "            if ((i*n_train_batches+index)%2 == 0):\n",
    "                for j in range(n_valid_batches):\n",
    "                    pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                                  valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                    errores.append(err_val)\n",
    "                # We get the validation error as the average over batches\n",
    "                error_valid[reg].append(np.mean(errores)) \n",
    "    print 'Reg: {: .4f} - Time taken: {:.4f}'.format(reg, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAAKFCAYAAAC6KZPUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142de610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(len(regs), sharex=True, sharey=True)\n",
    "f.set_size_inches(11,11)\n",
    "for i,reg in enumerate(regs):\n",
    "    axarr[i].plot(2*np.arange(len(error_valid[reg])), np.array(error_valid[reg]), marker='o')\n",
    "    axarr[i].set_title('Epoch:#10, Eta = 0.1, Reg = ' + str(reg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Effect of Regularization **\n",
    "\n",
    "Based on the plot above, when there is almost no regularization ($\\lambda$~0), the loss is the lowest. However, this might mean overfitting. In fact the performance does not significantly improve after **$\\lambda=0.01$**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch 0\n",
      "--- epoch 1\n",
      "--- epoch 2\n",
      "--- epoch 3\n",
      "--- epoch 4\n"
     ]
    }
   ],
   "source": [
    "reg = 0.01\n",
    "\n",
    "train, validate, test, predict = models(n_in, n_out, eta, reg)\n",
    "for i in xrange(n_epochs):\n",
    "    print '--- epoch',i\n",
    "    for index in xrange(n_train_batches):\n",
    "        pred, err = train(train_set[0][index * batch_size: (index + 1) * batch_size], \\\n",
    "                          train_set[1][index * batch_size: (index + 1) * batch_size])\n",
    "errors = []\n",
    "pred_vals = []\n",
    "for j in range(n_test_batches):\n",
    "    pred_val, err_val = test(test_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                          test_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "    errors.append(err_val) \n",
    "    pred_vals.append(pred_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (%): 89.8938\n",
      "Mean.Error 0.4554\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(pred_vals).flatten()\n",
    "y = np.array(test_set[1])[0:len(y_pred)]\n",
    "print 'Accuracy (%): {:.4f}'.format(np.mean(np.equal(y,y_pred))*100)\n",
    "print 'Mean.Error {:.4f}'.format(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. The Multilayer Perceptron (with one hidden layer)\n",
    "The multilayer perceptron can be understood as a logistic regression classifier in which the input is first transformed using a learnt non-linear transformation. The non-linear transformation is usually chosen to be either the logistic function or the $\\tanh$ function, and its purpose is to project the data into a space where it becomes linealry separable The output of this so-called hidden layer is then passed to the logistic regression graph that we have constructed in the first problem. In matrix notation:\n",
    "\n",
    "$$G(b^{(2)}+W^{(2)}(s(b^{(1)}+W^{(1)}x)))$$\n",
    "\n",
    "with bias vectors $b^{(1)}$, $b^{(2)}$; weight matrices $W^{(1)}$, $W^{(2)}$ and activation functions $G$ and $s$. Here is a diagram:\n",
    "\n",
    "![](http://deeplearning.net/tutorial/_images/mlp.png){:height=300 width=300}\n",
    "\n",
    "### Part A\n",
    "\n",
    "Using a similar architecture as in the first part and the same MNIST dataset, built a Theano graph for the multilayer perceptron, using the $\\tanh$ function as the non-linearity. Use $\\eta = 0.1$ and $\\lambda = 0.001$. Experiment with the batch size (use 20, 50, and 100 examples) and the number of units in your hidden layer (use 50, 100, and 200 units). For what combination of these parameters do you obtain the smallest value of the validation loss function after 50 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(rng, x, n_in, n_out):\n",
    "    w_vals = numpy.asarray(\n",
    "        rng.uniform(\n",
    "            low=-numpy.sqrt(6. / (n_in + n_out)),\n",
    "            high=numpy.sqrt(6. / (n_in + n_out)),\n",
    "            size=(n_in, n_out)\n",
    "        ),\n",
    "        dtype=theano.config.floatX\n",
    "    )\n",
    "    w = theano.shared(value=w_vals, name='w', borrow=True)\n",
    "    \n",
    "    b_vals = numpy.zeros((n_out,), dtype=theano.config.floatX)\n",
    "    b = theano.shared(value=b_vals, name='b', borrow=True)\n",
    "    \n",
    "    output = T.tanh(T.dot(x, w)+b)\n",
    "    return w, b, output\n",
    "\n",
    "def logistic_regressor(x, y, n_in, n_out):\n",
    "    \n",
    "    # initialize parameters with zeros (w: weights, b: bias)\n",
    "    w = theano.shared(value = np.zeros((n_in, n_out), dtype=theano.config.floatX), name='w', borrow=True)\n",
    "    b = theano.shared(value = numpy.zeros((n_out,),dtype=theano.config.floatX), name='b', borrow=True)\n",
    "\n",
    "    # probability for class-membership\n",
    "    p_y_given_x = T.nnet.softmax(T.dot(x,w)+b) \n",
    "\n",
    "    # the prediction model\n",
    "    prediction = T.argmax(p_y_given_x, axis=1) \n",
    "\n",
    "    # loss function\n",
    "    loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  \n",
    "\n",
    "    return w,b,prediction,loss\n",
    "\n",
    "def MLP_models(eta, reg, batch_size, n_hidden):    \n",
    "    # input\n",
    "    x = T.dmatrix(\"x\")\n",
    "    \n",
    "    # output\n",
    "    y = T.lvector(\"y\")\n",
    "    \n",
    "    \n",
    "    # random numger generator\n",
    "    rng = numpy.random.RandomState(1234)\n",
    "    \n",
    "    # input image size\n",
    "    n_in=28 * 28 \n",
    "\n",
    "    # class size (0~9)\n",
    "    n_out=10\n",
    "    \n",
    "    # hidden layer\n",
    "    h_w, h_b, h_output = hidden_layer(rng, x, n_in, n_hidden)\n",
    "    \n",
    "\n",
    "    # logistic regressor\n",
    "    w, b, prediction, loss = logistic_regressor(h_output, y, n_hidden, n_out)\n",
    "    \n",
    "\n",
    "    # cost (L2-regularization)\n",
    "    cost = loss.mean() + reg * ((h_w**2).sum() + (w ** 2).sum())\n",
    "    \n",
    "    # params\n",
    "    params = [h_w, h_b, w, b]\n",
    "    \n",
    "    # gradient descent\n",
    "    gds = [T.grad(cost, param) for param in params]\n",
    "    \n",
    "    # update rule\n",
    "    updates = [\n",
    "        (param, param - eta * gd)\n",
    "        for param, gd in zip(params, gds)\n",
    "    ]\n",
    "    \n",
    "    # training model    \n",
    "    train = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],\n",
    "              updates = updates,name='train')\n",
    "\n",
    "    # validate model\n",
    "    validate = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],name='validate')\n",
    "\n",
    "    # test model\n",
    "    test = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=[prediction, loss],name='test')\n",
    "    \n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  20, Hidden Unit: 50\n",
      "- Training Time: 81.4476\n",
      "- Validation Loss: 0.1421\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  20, Hidden Unit: 100\n",
      "- Training Time: 78.7153\n",
      "- Validation Loss: 0.1329\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  20, Hidden Unit: 200\n",
      "- Training Time: 121.4944\n",
      "- Validation Loss: 0.1335\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  50, Hidden Unit: 50\n",
      "- Training Time: 35.3382\n",
      "- Validation Loss: 0.1343\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  50, Hidden Unit: 100\n",
      "- Training Time: 52.2491\n",
      "- Validation Loss: 0.1282\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  50, Hidden Unit: 200\n",
      "- Training Time: 101.6748\n",
      "- Validation Loss: 0.1262\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  100, Hidden Unit: 50\n",
      "- Training Time: 42.6631\n",
      "- Validation Loss: 0.1363\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  100, Hidden Unit: 100\n",
      "- Training Time: 50.5669\n",
      "- Validation Loss: 0.1286\n",
      "\n",
      "\n",
      "Learning rate:  0.1, Regularization:  0.001, Batch Size:  100, Hidden Unit: 200\n",
      "- Training Time: 82.5535\n",
      "- Validation Loss: 0.1279\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "reg = 0.001\n",
    "batch_sizes = [20,50,100]\n",
    "hidden_units = [50, 100, 200]\n",
    "n_epochs = 50\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # number of mini-batches\n",
    "    n_train_batches = train_set[0].shape[0] // batch_size\n",
    "    n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "    n_test_batches = test_set[0].shape[0] // batch_size\n",
    "    \n",
    "    for hidden_unit in hidden_units:\n",
    "        print 'Learning rate: {: .1f}, Regularization: {: .3f}, Batch Size: {: d}, Hidden Unit: {:d}'\\\n",
    "            .format(eta, reg, batch_size, hidden_unit)\n",
    "        \n",
    "        train, validate, test = MLP_models(eta, reg, batch_size, hidden_unit)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for i in xrange(n_epochs):\n",
    "            for index in xrange(n_train_batches):                \n",
    "                train(train_set[0][index * batch_size: (index + 1) * batch_size], \\\n",
    "                      train_set[1][index * batch_size: (index + 1) * batch_size])\n",
    "                \n",
    "        print '- Training Time: {:.4f}'.format(time.time() - start_time)\n",
    "\n",
    "        errores = []\n",
    "        for j in range(n_valid_batches):\n",
    "            pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                                         valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "            errores.append(err_val)\n",
    "        print '- Validation Loss: {:.4f}'.format(np.mean(errores))\n",
    "        print '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Parameter\n",
    "\n",
    "The optimal parameter found was with batch size = 50 and number of hidden units = 200, where the validation loss was the lowest. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part B\n",
    "\n",
    "Stop the trainning at a convenient validation loss and use the trained classifier to predict for the test set. How much better is your test error as compared to the logistic regression classifier?\n",
    "\n",
    "*Hint 1:* The initialization of the weights matrix for the hidden layer must assure that the units (neurons) of the perceptron operate in a regime where information gets propagated. For the $\\tanh$ function, it is advisable to initialize with the interval $[-\\sqrt{\\frac{6}{fan_{in}+fan_{out}}},\\sqrt{\\frac{6}{fan_{in}+fan_{out}}}]$, where $fan_{in}$ is the number of units in the $(i-1)$-th layer, and $fan_{out}$ is the number of units in the i-th layer.\n",
    "\n",
    "*Hint 2:* You should feel free to get inspiration from [these tutorials](http://deeplearning.net/tutorial/mlp.html). However, we expect you to write your own code, inspired by the architecture shown in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "reg = 0.001\n",
    "batch_size = 50\n",
    "hidden_unit = 200\n",
    "n_epochs = 50\n",
    "\n",
    "train, validate, test = MLP_models(eta, reg, batch_size, hidden_unit)\n",
    "\n",
    "for i in xrange(n_epochs):\n",
    "    for index in xrange(n_train_batches):                \n",
    "        train(train_set[0][index * batch_size: (index + 1) * batch_size], \\\n",
    "              train_set[1][index * batch_size: (index + 1) * batch_size])\n",
    "\n",
    "errors = []    \n",
    "pred_vals = []\n",
    "for j in range(n_test_batches):\n",
    "    pred_val, err_val = test(test_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                          test_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "    errors.append(err_val) \n",
    "    pred_vals.append(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (%): 94.7600\n",
      "Mean.Error 0.1877\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(pred_vals).flatten()\n",
    "y = np.array(test_set[1])[0:len(y_pred)]\n",
    "print 'Accuracy (%): {:.4f}'.format(np.mean(np.equal(y,y_pred))*100)\n",
    "print 'Mean.Error {:.4f}'.format(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simply put, the accuracy has been significanlty improved."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
=======
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
>>>>>>> 8a09baa58aa931b846a703b38d999a223b6a8891
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
<<<<<<< HEAD
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
=======
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
>>>>>>> 8a09baa58aa931b846a703b38d999a223b6a8891
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
